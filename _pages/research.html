---
layout: archive
title: "Ongoing Research Projects with Earlham Students"
permalink: /research/
author_profile: true
---

{% include base_path %}

<!--  <h1> Ongoing Research Projects with Earlham Students </h1> -->

<h2 id="aging"> Aging Analysis on Veteran Dataset </h2>
<p> An extension of our previous work to investigate whether paralinguistic vocal attributes improve estimates of the age and risk of mortality in older adults. We obtain interviews of male US veterans from the Veteran History Project database managed by the Library of Congress. We diarize the audio recordings, measure vocal features, and match mortality information. Veterans are randomly split into training and testing subsets to generate estimations of vocal age and years of life remaining. Computational analyses produced vocal age estimates that were correlated with both age and predicted time until death when age was held constant. We further extend this work by performing language analysis on the transcripts derived from audio recordings. To enrich our analysis and achieve a greater degree of accuracy, we obtained data from the National Death Index, which provides specific causes of death among the veterans, enabling us to establish a more direct correlation between the features extracted from both the audio recordings and their transcripts, and the prevalence of certain diseases. This study aims to uncover nuanced linguistic patterns and potential indicators of mental and physical health conditions that might not be immediately evident.
<br>
<br>
Read our previous publication in the Journal of Gerontology <a href="https://pubmed.ncbi.nlm.nih.gov/37366320/" target="_blank" rel="noopener noreferrer">here</a>.
<p></p> 
<img src="https://www.ncbi.nlm.nih.gov/pmc/articles/instance/10733188/bin/glad154_fig4.jpg" width="500px" height="700px">
</p>


<h2 id="forecast"> LLM Event Forecasting </h2>
<br>
<br>


<h2 id="bias"> Evaluating Bias in Facial Expression Recognition Systems </h2>
<br>
<br>


<h2 id="dictionary"> (Completed project under submission) Word Definitions from Large Language Models </h2>
<p>Dictionary definitions are historically the arbitrator of what words mean, but this primacy has come under threat by recent progress in NLP, including word embeddings and generative models like ChatGPT. We present an exploratory study of the degree of alignment between word definitions from classical dictionaries and these newer computational artifacts. Specifically, we compare definitions from three published dictionaries to those generated from variants of ChatGPT. We show that (i) definitions from different traditional dictionaries exhibit more surface form similarity than do model-generated definitions, (ii) that the ChatGPT definitions are highly accurate, comparable to traditional dictionaries, and (iii) ChatGPT-based embedding definitions retain their accuracy even on low frequency words, much better than GloVE and FastText word embeddings.
<br>
<br>
Read the current state of our manuscript <a href="https://arxiv.org/pdf/2311.06362" target="_blank" rel="noopener noreferrer">here</a>.
<p></p> 
<img src="https://github.com/Yinsight/Yinsight.github.io/blob/master/images/matched_among_gpt_and_dict.png?raw=true" width="400px" height="500px">
</p>


<h2 id="audiobook"> (Completed project under submission) Prosody Analysis of Audiobooks </h2>
<p>Recent advances in text-to-speech have made it possible to generate natural-sounding audio from text. However, audiobook narrations involve dramatic vocalizations and intonations by the reader, with greater reliance on emotions, dialogues, and descriptions in the narrative. Using our dataset of 93 aligned book-audiobook pairs, we present improved models for prosody prediction properties (pitch, volume, and rate of speech) from narrative text using language modeling. Our predicted prosody attributes correlate much better with human audiobook readings than results from a state-of-the-art commercial TTS system: our predicted pitch shows a higher correlation with human reading for 22 out of the 24 books, while our predicted volume attribute proves more similar to human reading for 23 out of the 24 books. Finally, we present a human evaluation study to quantify the extent that people prefer prosody-enhanced audiobook readings over commercial text-to-speech systems.
<br>
<br>
Read the current state of our manuscript <a href="https://arxiv.org/pdf/2310.06930" target="_blank" rel="noopener noreferrer">here</a>.
<p></p> 
<img src="https://github.com/Yinsight/Yinsight.github.io/blob/master/images/test_gt_pitch2.png?raw=true">
</p>
